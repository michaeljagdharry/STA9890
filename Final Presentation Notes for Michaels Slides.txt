Training and Test R^2s
Here we see boxplots of the training and test R^2s for each of the four models. Each of the regularization methods perform very well, each around the neighborhood of about .93. Surprisingly, the random forest performed poorly compared to these regularization methods. However, since random forests require many observations per predictor to perform well, that we only have 480 observations and 43 variables means that we only have about 11 observations per predictor, which could explain the underperformance. 
 
Suppose the true relationship between the predictors and the response is a smooth function in Rp. We know that the regularization methods produce a smooth p-dimensional prediction function, as they are really extensions of the ordinary least squares regression. So if the data comes from a smooth p-dimensional surface, then such methods should fit the data well. In contrast, the random forest, which is a p-dimensional step function, and therefore is not smooth, will introduce greater prediction error. The p=1 case is illustrated below.

Training and Test Residuals
Here we see boxplots for the training and test residuals across the four different models. Observing the boxplots, we see that they are symmetric about their mean, which is approximately 0, and that the points cluster around the mean. Looking at the training residuals, we see the random forest model has the greatest residual variance amongst all models. For Lasso specifically, we observe an increase in the range and interquartile range as we go from the training residuals to test residuals, suggesting that the test residual variance for lasso is greater than the training residual variance. However the Ridge and El-net methods appear to exhibit the opposite behavior. We see that the sizes of the test boxplots for ridge and elnet are smaller than the corresponding training boxplots, suggesting a decrease in the residual variances for these methods. 

CV Curves
Here are the 10 Fold Cross Validation Curves for each of the three regularization methods. We know that ridge doesn’t perform variable selection, so we see all 43 variables present. The average runtime across the 100 samples is .098 seconds. Elastic Net Regression selects for 20 variables and has an average runtime of .079 seconds. Finally, lasso regression selects for 18 variables with an average runtime of .074 seconds. 

90% Test Interval and Runtimes
Here is a table of the 5th and 95th percentiles for the test R^2s for each of the models, along with their average runtimes on all of the data. According to the table, we see that the range of R^2’s for the random forest, .774 to .852, is completely below the range for the regularization methods, which a minimum at .922 for ridge to a maximum of .962 for lasso. We also see that the runtimes for the regularization methods are 6 to 10 times faster than the runtime for random forest. Since not only is the worst performing regularization model better than the best performing random forest model, and the regularization models run faster, we can conclude that the regularization models are clearly preferrable to the random forest. Now I will pass it off to Nick who will talk about the Coefficient Barplots. 
